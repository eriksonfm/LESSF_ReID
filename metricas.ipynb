{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import numpy as np\n","from sklearn.cluster import KMeans\n","import matplotlib.pyplot as plt\n","from datasetUtils import load_from_Jadson\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay"]},{"cell_type":"markdown","metadata":{},"source":["######## DADOS GLOBAIS ##########"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labels_teste = ''\n","labels_validation = ''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features_teste = ''\n","features_validation = ''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base_name_dir = \"/hadatasets/Synthetic-Realities/20-spoofing-mpad/2020-plosone-recod-mpad\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["distance_matrices = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def calc_predito(clusters, features, labels_ground_truth, modelo):\n","    \n","    kmeans = KMeans(n_clusters=clusters)\n","        \n","    # features = features/torch.norm(features, dim=1, keepdim=True)\n","    # distance_matrix = 1.0 - torch.mm(features, features.T)\n","    # \n","    # features = features/torch.norm(features, dim=1, keepdim=True)\n","    # distance_matrix = 1.0 - torch.mm(features, features.T)\n","    \n","    # distance_ensemble = (distance_R50 + distance_OSN + distance_DEN)/3\n","\n","    # Salvar as tres, carregar as 3 e colocar no próximo argumento\n","    if modelo == \"mean\":\n","        distance_matrices_array = np.array(distance_matrices)\n","        mean_distance_matrix = np.mean(distance_matrices_array, axis=0)\n","        distance_matrix = mean_distance_matrix\n","        \n","    else:\n","        features = features/torch.norm(features, dim=1, keepdim=True)\n","        distance_matrix = 1.0 - torch.mm(features, features.T)\n","        # colocar em um vetor global para fazer a mistura depois\n","        \n","        distance_matrices.append(distance_matrix)\n","        \n","    kmeans.fit(distance_matrix) \n","    labels_kmt = kmeans.labels_\n","    predito = np.zeros(len(labels_ground_truth), dtype=int)\n","    zero_idx = np.where(labels_kmt==0)[0]\n","    one_idx  = np.where(labels_kmt==1)[0]\n","    GT_zero = labels_ground_truth[zero_idx]\n","    labels,frequecia = np.unique(GT_zero, return_counts=True)\n","        \n","    if len(labels)==2 :\n","        if frequecia[0] > frequecia[1] : \n","            predito[zero_idx] = labels[0]\n","            predito[one_idx]  = labels[1]\n","            \n","        else: \n","            predito[zero_idx] = labels[1]\n","            predito[one_idx]  = labels[0]\n","                     \n","    return predito "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def medidas(GT, predito, modelo, k=0, lambda_hard=0,idx=0, grupo='test'):\n","    y_true = GT\n","    y_pred = predito\n","    confusion = confusion_matrix(GT, predito,normalize='true')\n","    \n","    \n","    disp = ConfusionMatrixDisplay(confusion)\n","    disp.plot()\n","    plt.savefig(f'resultados/MC_{k}_{lambda_hard}_{idx}_{grupo}_{modelo}.png')\n","    plt.close()\n","    \n","    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","    # calculando as métricas iniciais\n","    \n","    # # Calcular a acurácia (Accuracy)\n","    accuracy = accuracy_score(y_true, y_pred)\n","        \n","    # Calcular a precisão (Precision)\n","    precision = precision_score(y_true, y_pred, zero_division=\"warn\")\n","    \n","    # Calcular o recall (Sensibilidade)\n","    recall = recall_score(y_true, y_pred)\n","     \n","    # Calcular o F1-Score\n","    f1_score = f1_score(y_true, y_pred)\n","    \n","    TP = confusion[0,0]\n","    FN = confusion[0,1]\n","    FP = confusion[1,0]\n","    TN = confusion[1,1]\n","    \n","    # # Calcular o APCER\n","    # APCER = FN / (TP + FN)\n","         \n","    # # Calcular o BPCER\n","    # BPCER = FP / (TN + FP)\n","    \n","    return [accuracy, precision, recall, f1_score], ['ACCURACY', 'PRECISION', 'RECALL', 'F1_SCORE'] #incluir APCER e BPCER\n","    \n","def desenha_metricas(GT, features, labels_ground_truth, modelo, k=0, lambda_hard=0, idx=0, grupo='test', show_all=True):\n","        \n","    predito = calc_predito(clusters=2,features=features,labels_ground_truth=labels_ground_truth, modelo=modelo)\n","    metricas, rotulos = medidas(GT=GT,predito=predito, modelo=modelo, k=k, lambda_hard=lambda_hard, idx=idx, grupo=grupo)\n"," \n","    accuracy  = metricas[0]\n","    precision = metricas[1]\n","    recall    = metricas[2]\n","    f1_score  = metricas[3]\n","    #APCER     = metricas[4]\n","    #BPCER     = metricas[5]\n","\n","    # Criar o gráfico de barras\n","    plt.bar(rotulos, metricas)\n","\n","    # Adicionar rótulos e título\n","    plt.xlabel(\"Métricas\")\n","    plt.ylabel(\"Valores\")\n","    plt.title(\"Comparação das métricas\")\n","\n","    # Exibir o gráfico\n","    if (show_all == True):\n","        plt.show()\n","    \n","    plt.savefig(f'resultados/grafico_{k}_{lambda_hard}_{idx}_{grupo}_{modelo}.png')\n","    plt.close()\n","    return rotulos, metricas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def metricas(k, lambda_hard, modelo):\n","    \n","    #carregando labels\n","    labels_teste = np.load(\"resultados/labels_test_ruido.npy\", allow_pickle=True).astype(int)\n","    labels_validation = np.load(\"resultados/labels_validation_ruido.npy\", allow_pickle=True).astype(int)\n","\n","    #corregando dados\n","    features_teste = torch.load(\"resultados/test_ruido_\" + modelo + \".pt\")\n","    features_validation = torch.load(\"resultados/validation_ruido_\" + modelo +\".pt\")\n","\n","    # executando com conjunto de testes\n","    GT = load_from_Jadson(\"csvs/test_motog5.csv\", base_name_dir, True)\n","    GT = np.array([ int(item[1]) for item in GT])\n","    \n","    tentativas =10\n","    metricas_t = []\n","    for i in range(tentativas):\n","        rotulos_t, metricas = desenha_metricas(GT=GT, features=features_teste, labels_ground_truth=labels_teste, modelo=modelo, k=k, lambda_hard=lambda_hard,idx=i, grupo='test', show_all=False)\n","        metricas_t.append(metricas)\n","    metricas_t = np.array(metricas_t)\n","\n","    # executando com conjunto de validação\n","    GT = load_from_Jadson(\"csvs/val_motog5.csv\", base_name_dir, True)\n","    GT = np.array([ int(item[1]) for item in GT])\n","    metricas_v = []\n","    for i in range(tentativas):\n","        rotulos_v, metricas = desenha_metricas(GT=GT, features=features_validation, labels_ground_truth=labels_validation, modelo=modelo, k=k, lambda_hard=lambda_hard,idx=i, grupo='valid', show_all=False)\n","        metricas_v.append(metricas)\n","    metricas_v = np.array(metricas_v)\n","    \n","    return metricas_t, metricas_v"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
