{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T19:03:25.251180Z",
     "iopub.status.busy": "2024-03-20T19:03:25.250893Z",
     "iopub.status.idle": "2024-03-21T03:30:19.835758Z",
     "shell.execute_reply": "2024-03-21T03:30:19.833274Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchreid/reid/metrics/rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/emorais/repos/LESSF_ReID-working/DCNNs.py:18: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** inicio do teste com ruido em k:4 e lambda_hard:0.0 ****\n",
      "Num GPU's: 3\n",
      "Allocated GPU's for model: [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"/home/emorais/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "Successfully loaded imagenet pretrained weights from \"/home/emorais/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: (38400, 3)\n",
      "Gallery Size: (24000, 3)\n",
      "Query Size: (9600, 3)\n",
      "Validating mobilenet on Jadson ...\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n",
      "passou aqui\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 98\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**** inicio do teste com ruido em k:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m e lambda_hard:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlambda_hard\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ****\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteste-04-ruido-norm-90epocas-MNETv3_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlambda_hard\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.5e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.04\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.999\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mk1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlambda_hard\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_hard\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnumber_of_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmomentum_on_feature_extraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mJadson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdir_to_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdir_to_save_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetrics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43muse_ruido\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metodo \u001b[38;5;129;01min\u001b[39;00m models_name \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    101\u001b[0m     metricas_t, metricas_v, rotulos_t, rotulos_v \u001b[38;5;241m=\u001b[39m metricas(k\u001b[38;5;241m=\u001b[39mk, lambda_hard\u001b[38;5;241m=\u001b[39mlambda_hard, modelo\u001b[38;5;241m=\u001b[39mmetodo)\n",
      "File \u001b[0;32m~/repos/LESSF_ReID-working/main.py:77\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(gpu_ids, base_lr, P, K, tau, beta, k1, sampling, lambda_hard, number_of_iterations, momentum_on_feature_extraction, target, dir_to_save, dir_to_save_metrics, version, eval_freq, use_ruido)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, TOTAL_MODELOS):\n\u001b[1;32m     76\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidating \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (models_name[model], target))\n\u001b[0;32m---> 77\u001b[0m \tcmc, mAP, mat \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries_images_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgallery_images_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_online\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu_indexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \tdistmat\u001b[38;5;241m.\u001b[39mappend(mat)\n\u001b[1;32m     80\u001b[0m distmat_ensembled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(distmat,\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/repos/LESSF_ReID-working/DCNNs.py:320\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(queries, gallery, model, rerank, gpu_index)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(queries, gallery, model, rerank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, gpu_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    319\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 320\u001b[0m     queries_fvs \u001b[38;5;241m=\u001b[39m \u001b[43mextractFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gallery_fvs \u001b[38;5;241m=\u001b[39m extractFeatures(gallery, model, \u001b[38;5;241m500\u001b[39m, gpu_index)\n\u001b[1;32m    323\u001b[0m     queries_fvs \u001b[38;5;241m=\u001b[39m queries_fvs\u001b[38;5;241m/\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnorm(queries_fvs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/repos/LESSF_ReID-working/featureExtraction.py:149\u001b[0m, in \u001b[0;36mextractFeatures\u001b[0;34m(subset, model, batch_size, gpu_index, eval_mode)\u001b[0m\n\u001b[1;32m    147\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    148\u001b[0m subset_fvs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m#fvs = getFVs(batch, model, gpu_index)\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    153\u001b[0m         batch_gpu \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mcuda(gpu_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from main import *\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from datasetUtils import load_from_Jadson\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# parser = argparse.ArgumentParser(description='Define the UDA parameters')\n",
    "#\n",
    "# parser.add_argument('--gpu_ids', type=str, default=\"7\", help='GPU IDs')\n",
    "# parser.add_argument('--lr', type=float, default=3.5e-4, help='Learning Rate')\n",
    "# parser.add_argument('--P', type=int, default=16, help='Number of Persons')\n",
    "# parser.add_argument('--K', type=int, default=4, help='Number of samples per person')\n",
    "# parser.add_argument('--tau', type=float, default=0.05, help='tau value used on softmax triplet loss')\n",
    "# parser.add_argument('--beta', type=float, default=0.999, help='beta used on self-Ensembling')\n",
    "# parser.add_argument('--k1', type=int, default=30, help='k on k-Reciprocal Encoding')\n",
    "# parser.add_argument('--sampling', type=str, default=\"mean\", help='Mean or Random feature vectors to be prototype')\n",
    "# parser.add_argument('--lambda_hard', type=float, default=0.5, help='tuning prameter of Softmax Triplet Loss')\n",
    "# parser.add_argument('--num_iter', type=int, default=400, help='Number of iterations on an epoch')\n",
    "# parser.add_argument('--momentum_on_feature_extraction', type=int, default=0,\n",
    "# help='If it is the momentum used on feature extraction')\n",
    "# parser.add_argument('--target', type=str, help='Name of target dataset')\n",
    "# parser.add_argument('--path_to_save_models', type=str, help='Path to save models')\n",
    "# parser.add_argument('--path_to_save_metrics', type=str, help='Path to save metrics (mAP, CMC, ...)')\n",
    "# parser.add_argument('--version', type=str, help='Path to save models')\n",
    "# parser.add_argument('--eval_freq', type=int, help='Evaluation Frequency along training')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# gpu_ids = args.gpu_ids\n",
    "# base_lr = args.lr\n",
    "# P = args.P\n",
    "# K = args.K\n",
    "\n",
    "# tau = args.tau\n",
    "# beta = args.beta\n",
    "# k1 = args.k1\n",
    "# sampling  = args.sampling\n",
    "#\n",
    "# lambda_hard = args.lambda_hard\n",
    "# number_of_iterations = args.num_iter\n",
    "# momentum_on_feature_extraction = bool(args.momentum_on_feature_extraction)\n",
    "# target = args.target\n",
    "# dir_to_save = args.path_to_save_models\n",
    "# dir_to_save_metrics = args.path_to_save_metrics\n",
    "# version = args.version\n",
    "# eval_freq = args.eval_freq\n",
    "# main.py --gpu_ids=0,1,2,3 --lr=3.5e-4 --P=16 --K=12 --tau=0.04 --beta=0.999 --k1=30 --sampling=mean --lambda_hard=0.5 --num_iter=7 --momentum_on_feature_extraction=0 --target=Duke --path_to_save_models=models --path_to_save_metrics=metrics --version=version_name --eval_freq=5\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Função para exibir a imagem usando HTML\n",
    "def exibir_imagem(imagem_path):\n",
    "    return f'<img src=\"{imagem_path}\" width=\"400\">'\n",
    "\n",
    "\n",
    "from metricas import *\n",
    "\n",
    "html_content= \"\"\n",
    "df = pd.DataFrame({\n",
    "    'k':[], \n",
    "    'lambda_hard':[],\n",
    "    'modelo':[],\n",
    "    'matriz_confusao':[], \n",
    "    'Acuracia':[], \n",
    "    'Precisao':[],\n",
    "    'Recall':[],\n",
    "    'F1-score':[],\n",
    "    'Grafico':[],\n",
    "    'Tipo':[]\n",
    "    })\n",
    "\n",
    "gpus = \"0,3,4\" \n",
    "for k in [4]:\n",
    "    for lambda_hard in [ 0.0 ]:\n",
    "                \n",
    "        print(f\"**** inicio do teste com ruido em k:{k} e lambda_hard:{lambda_hard} ****\")\n",
    "        \n",
    "        version = f\"teste-04-ruido-norm-90epocas-MNETv3_{k}_{lambda_hard}\"\n",
    "        \n",
    "        main(gpu_ids=gpus,base_lr=3.5e-4,P=16,K=k,tau=0.04,beta=0.999,k1=30,sampling=\"random\",lambda_hard=lambda_hard,number_of_iterations=7,momentum_on_feature_extraction=0,target=\"Jadson\",dir_to_save=\"models\",dir_to_save_metrics=\"metrics\",version=version,eval_freq=5,use_ruido=True)\n",
    "        \n",
    "        for metodo in models_name + [\"mean\"]:\n",
    "            metricas_t, metricas_v, rotulos_t, rotulos_v = metricas(k=k, lambda_hard=lambda_hard, modelo=metodo)\n",
    "            linha = {\n",
    "                'k':            [k], \n",
    "                'lambda_hard':  [lambda_hard],\n",
    "                'modelo':       [metodo],\n",
    "                'Tipo':         'Test'\n",
    "            }\n",
    "            for count in range( 0, metricas_t.shape[0] ):\n",
    "                for m in range( 0, metricas_t.shape[1] ):\n",
    "                    linha[rotulos_t[m]] = metricas_t[count][m]\n",
    "                    \n",
    "                \n",
    "                linha['matriz_confusao'] = f'resultados/MC_{k}_{lambda_hard}_{count}_{metodo}_test.png'\n",
    "                linha['Grafico'] = f'resultados/grafico_{k}_{lambda_hard}_{count}_{metodo}_test.png'\n",
    "                df = pd.concat( [df, pd.DataFrame(linha)], axis=0)\n",
    "             \n",
    "            linha = {\n",
    "               'k':             [k], \n",
    "               'lambda_hard':   [lambda_hard],\n",
    "               'modelo':        [metodo],\n",
    "               'Tipo':          'Valid'\n",
    "             }\n",
    "            for count in range( 0, metricas_v.shape[0] ):\n",
    "                for m in range( 0, metricas_v.shape[1] ):\n",
    "                    linha[rotulos_v[m]] = metricas_v[count][m] \n",
    "               \n",
    "                linha['Grafico'] = f'resultados/grafico_{k}_{lambda_hard}_{count}_{metodo}_valid.png'\n",
    "                linha['matriz_confusao'] = f'resultados/MC_{k}_{lambda_hard}_{count}_{metodo}_valid.png' \n",
    "                df = pd.concat( [df, pd.DataFrame(linha)], axis=0)\n",
    "        \n",
    "        # Aplicar a função à coluna 'imagem' e criar uma nova coluna 'imagem_exibicao'\n",
    "        df['MC'] = df['matriz_confusao'].apply(exibir_imagem)\n",
    "        df['GR'] = df['Grafico'].apply(exibir_imagem)\n",
    "        \n",
    "        html_content = df[['k', \n",
    "                           'lambda_hard', \n",
    "                           'Tipo', \n",
    "                           'modelo'] + \n",
    "                           rotulos_v[:8] + \n",
    "                           ['MC', \n",
    "                           'GR']].to_html(escape=False, index=False)\n",
    "        # salvando df em arquivo html\n",
    "        # Use BeautifulSoup para formatar o HTML\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        formatted_html = soup.prettify()\n",
    "        \n",
    "        # Salve o HTML em um arquivo\n",
    "        head = \"<!DOCTYPE html>\\n<html lang='pt-br'>\\n<head>\\n  <meta charset='UTF-8'>\\n  <meta name='viewport' content='width=device-width, initial-scale=1.0'>\\n  <style>\\n    table {\\n      width: 100%;\\n      border-collapse: collapse;\\n    }\\n    th, td {\\n      border: 1px solid #ddd;\\n      padding: 8px;\\n      text-align: left;\\n    }\\n    th {\\n      background-color: #f2f2f2;\\n    }\\n    thead th {\\n      position: sticky;\\n      top: 0;\\n      z-index: 1;\\n      background-color: #f2f2f2;    }\\n  </style>\\n    <title>Relatório Parcial</title>\\n</head>\\n<body>\"\n",
    "        with open('relatorio-APCER-BPCER-ACER-silhouette-ward-90epocas-ruido-norm-MNETv3.html', 'w', encoding='utf-8') as file:\n",
    "            file.write(head)\n",
    "            file.write(formatted_html)\n",
    "            file.write('</body></html>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T03:30:19.846583Z",
     "iopub.status.busy": "2024-03-21T03:30:19.844539Z",
     "iopub.status.idle": "2024-03-21T03:30:19.868616Z",
     "shell.execute_reply": "2024-03-21T03:30:19.867886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exibir o DataFrame com as imagens\n",
    "display(HTML(html_content))\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
