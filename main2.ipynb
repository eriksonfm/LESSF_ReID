{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T19:03:25.251180Z",
     "iopub.status.busy": "2024-03-20T19:03:25.250893Z",
     "iopub.status.idle": "2024-03-21T03:30:19.835758Z",
     "shell.execute_reply": "2024-03-21T03:30:19.833274Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchreid/reid/metrics/rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/emorais/repos/LESSF_ReID-working/DCNNs.py:18: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** inicio do teste com ruido em k:4 e lambda_hard:0.0 ****\n",
      "Num GPU's: 1\n",
      "Allocated GPU's for model: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Base_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Base_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"/home/emorais/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "Successfully loaded imagenet pretrained weights from \"/home/emorais/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: (38400, 3)\n",
      "Gallery Size: (24000, 3)\n",
      "Query Size: (9600, 3)\n",
      "Validating convnext on Jadson ...\n",
      "Features extracted in 68.95 seconds\n",
      "Features extracted in 137.14 seconds\n",
      "Computing CMC and mAP ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from main import *\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from datasetUtils import load_from_Jadson\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# parser = argparse.ArgumentParser(description='Define the UDA parameters')\n",
    "#\n",
    "# parser.add_argument('--gpu_ids', type=str, default=\"7\", help='GPU IDs')\n",
    "# parser.add_argument('--lr', type=float, default=3.5e-4, help='Learning Rate')\n",
    "# parser.add_argument('--P', type=int, default=16, help='Number of Persons')\n",
    "# parser.add_argument('--K', type=int, default=4, help='Number of samples per person')\n",
    "# parser.add_argument('--tau', type=float, default=0.05, help='tau value used on softmax triplet loss')\n",
    "# parser.add_argument('--beta', type=float, default=0.999, help='beta used on self-Ensembling')\n",
    "# parser.add_argument('--k1', type=int, default=30, help='k on k-Reciprocal Encoding')\n",
    "# parser.add_argument('--sampling', type=str, default=\"mean\", help='Mean or Random feature vectors to be prototype')\n",
    "# parser.add_argument('--lambda_hard', type=float, default=0.5, help='tuning prameter of Softmax Triplet Loss')\n",
    "# parser.add_argument('--num_iter', type=int, default=400, help='Number of iterations on an epoch')\n",
    "# parser.add_argument('--momentum_on_feature_extraction', type=int, default=0,\n",
    "# help='If it is the momentum used on feature extraction')\n",
    "# parser.add_argument('--target', type=str, help='Name of target dataset')\n",
    "# parser.add_argument('--path_to_save_models', type=str, help='Path to save models')\n",
    "# parser.add_argument('--path_to_save_metrics', type=str, help='Path to save metrics (mAP, CMC, ...)')\n",
    "# parser.add_argument('--version', type=str, help='Path to save models')\n",
    "# parser.add_argument('--eval_freq', type=int, help='Evaluation Frequency along training')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# gpu_ids = args.gpu_ids\n",
    "# base_lr = args.lr\n",
    "# P = args.P\n",
    "# K = args.K\n",
    "\n",
    "# tau = args.tau\n",
    "# beta = args.beta\n",
    "# k1 = args.k1\n",
    "# sampling  = args.sampling\n",
    "#\n",
    "# lambda_hard = args.lambda_hard\n",
    "# number_of_iterations = args.num_iter\n",
    "# momentum_on_feature_extraction = bool(args.momentum_on_feature_extraction)\n",
    "# target = args.target\n",
    "# dir_to_save = args.path_to_save_models\n",
    "# dir_to_save_metrics = args.path_to_save_metrics\n",
    "# version = args.version\n",
    "# eval_freq = args.eval_freq\n",
    "# main.py --gpu_ids=0,1,2,3 --lr=3.5e-4 --P=16 --K=12 --tau=0.04 --beta=0.999 --k1=30 --sampling=mean --lambda_hard=0.5 --num_iter=7 --momentum_on_feature_extraction=0 --target=Duke --path_to_save_models=models --path_to_save_metrics=metrics --version=version_name --eval_freq=5\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Função para exibir a imagem usando HTML\n",
    "def exibir_imagem(imagem_path):\n",
    "    return f'<img src=\"{imagem_path}\" width=\"400\">'\n",
    "\n",
    "\n",
    "from metricas import *\n",
    "\n",
    "html_content= \"\"\n",
    "df = pd.DataFrame({\n",
    "    'k':[], \n",
    "    'lambda_hard':[],\n",
    "    'modelo':[],\n",
    "    'matriz_confusao':[], \n",
    "    'Acuracia':[], \n",
    "    'Precisao':[],\n",
    "    'Recall':[],\n",
    "    'F1-score':[],\n",
    "    'Grafico':[],\n",
    "    'Tipo':[]\n",
    "    })\n",
    "\n",
    "gpus = \"0\" \n",
    "for k in [4]:\n",
    "    for lambda_hard in [ 0.0 ]:\n",
    "                \n",
    "        print(f\"**** inicio do teste com ruido em k:{k} e lambda_hard:{lambda_hard} ****\")\n",
    "        \n",
    "        version = f\"teste-04-ruido-norm-90epocas-ConvNext_{k}_{lambda_hard}\"\n",
    "        \n",
    "        main(gpu_ids=gpus,base_lr=3.5e-4,P=16,K=k,tau=0.04,beta=0.999,k1=30,sampling=\"random\",lambda_hard=lambda_hard,number_of_iterations=7,momentum_on_feature_extraction=0,target=\"Jadson\",dir_to_save=\"models\",dir_to_save_metrics=\"metrics\",version=version,eval_freq=5,use_ruido=True)\n",
    "        \n",
    "        for metodo in models_name + [\"mean\"]:\n",
    "            metricas_t, metricas_v, rotulos_t, rotulos_v = metricas(k=k, lambda_hard=lambda_hard, modelo=metodo)\n",
    "            linha = {\n",
    "                'k':            [k], \n",
    "                'lambda_hard':  [lambda_hard],\n",
    "                'modelo':       [metodo],\n",
    "                'Tipo':         'Test'\n",
    "            }\n",
    "            for count in range( 0, metricas_t.shape[0] ):\n",
    "                for m in range( 0, metricas_t.shape[1] ):\n",
    "                    linha[rotulos_t[m]] = metricas_t[count][m]\n",
    "                    \n",
    "                \n",
    "                linha['matriz_confusao'] = f'resultados/MC_{k}_{lambda_hard}_{count}_{metodo}_test.png'\n",
    "                linha['Grafico'] = f'resultados/grafico_{k}_{lambda_hard}_{count}_{metodo}_test.png'\n",
    "                df = pd.concat( [df, pd.DataFrame(linha)], axis=0)\n",
    "             \n",
    "            linha = {\n",
    "               'k':             [k], \n",
    "               'lambda_hard':   [lambda_hard],\n",
    "               'modelo':        [metodo],\n",
    "               'Tipo':          'Valid'\n",
    "             }\n",
    "            for count in range( 0, metricas_v.shape[0] ):\n",
    "                for m in range( 0, metricas_v.shape[1] ):\n",
    "                    linha[rotulos_v[m]] = metricas_v[count][m] \n",
    "               \n",
    "                linha['Grafico'] = f'resultados/grafico_{k}_{lambda_hard}_{count}_{metodo}_valid.png'\n",
    "                linha['matriz_confusao'] = f'resultados/MC_{k}_{lambda_hard}_{count}_{metodo}_valid.png' \n",
    "                df = pd.concat( [df, pd.DataFrame(linha)], axis=0)\n",
    "        \n",
    "        # Aplicar a função à coluna 'imagem' e criar uma nova coluna 'imagem_exibicao'\n",
    "        df['MC'] = df['matriz_confusao'].apply(exibir_imagem)\n",
    "        df['GR'] = df['Grafico'].apply(exibir_imagem)\n",
    "        \n",
    "        html_content = df[['k', \n",
    "                           'lambda_hard', \n",
    "                           'Tipo', \n",
    "                           'modelo'] + \n",
    "                           rotulos_v[:8] + \n",
    "                           ['MC', \n",
    "                           'GR']].to_html(escape=False, index=False)\n",
    "        # salvando df em arquivo html\n",
    "        # Use BeautifulSoup para formatar o HTML\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        formatted_html = soup.prettify()\n",
    "        \n",
    "        # Salve o HTML em um arquivo\n",
    "        head = \"<!DOCTYPE html>\\n<html lang='pt-br'>\\n<head>\\n  <meta charset='UTF-8'>\\n  <meta name='viewport' content='width=device-width, initial-scale=1.0'>\\n  <style>\\n    table {\\n      width: 100%;\\n      border-collapse: collapse;\\n    }\\n    th, td {\\n      border: 1px solid #ddd;\\n      padding: 8px;\\n      text-align: left;\\n    }\\n    th {\\n      background-color: #f2f2f2;\\n    }\\n    thead th {\\n      position: sticky;\\n      top: 0;\\n      z-index: 1;\\n      background-color: #f2f2f2;    }\\n  </style>\\n    <title>Relatório Parcial</title>\\n</head>\\n<body>\"\n",
    "        with open('relatorio-APCER-BPCER-ACER-silhouette-ward-90epocas-ruido-norm-ConvNext.html', 'w', encoding='utf-8') as file:\n",
    "            file.write(head)\n",
    "            file.write(formatted_html)\n",
    "            file.write('</body></html>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T03:30:19.846583Z",
     "iopub.status.busy": "2024-03-21T03:30:19.844539Z",
     "iopub.status.idle": "2024-03-21T03:30:19.868616Z",
     "shell.execute_reply": "2024-03-21T03:30:19.867886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exibir o DataFrame com as imagens\n",
    "display(HTML(html_content))\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
