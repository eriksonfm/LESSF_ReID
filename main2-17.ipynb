{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:17:03.242377Z",
     "iopub.status.busy": "2024-01-12T16:17:03.241277Z",
     "iopub.status.idle": "2024-01-12T16:17:27.456967Z",
     "shell.execute_reply": "2024-01-12T16:17:27.455718Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/torchreid/reid/metrics/rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n",
      "/home/emorais/miniconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/emorais/repos/LESSF_ReID/DCNNs.py:18: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** inicio do teste com ruido em k:4 e lambda_hard:0.0 ****\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from main import *\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from datasetUtils import load_from_Jadson\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# parser = argparse.ArgumentParser(description='Define the UDA parameters')\n",
    "#\n",
    "# parser.add_argument('--gpu_ids', type=str, default=\"7\", help='GPU IDs')\n",
    "# parser.add_argument('--lr', type=float, default=3.5e-4, help='Learning Rate')\n",
    "# parser.add_argument('--P', type=int, default=16, help='Number of Persons')\n",
    "# parser.add_argument('--K', type=int, default=4, help='Number of samples per person')\n",
    "# parser.add_argument('--tau', type=float, default=0.05, help='tau value used on softmax triplet loss')\n",
    "# parser.add_argument('--beta', type=float, default=0.999, help='beta used on self-Ensembling')\n",
    "# parser.add_argument('--k1', type=int, default=30, help='k on k-Reciprocal Encoding')\n",
    "# parser.add_argument('--sampling', type=str, default=\"mean\", help='Mean or Random feature vectors to be prototype')\n",
    "# parser.add_argument('--lambda_hard', type=float, default=0.5, help='tuning prameter of Softmax Triplet Loss')\n",
    "# parser.add_argument('--num_iter', type=int, default=400, help='Number of iterations on an epoch')\n",
    "# parser.add_argument('--momentum_on_feature_extraction', type=int, default=0,\n",
    "# help='If it is the momentum used on feature extraction')\n",
    "# parser.add_argument('--target', type=str, help='Name of target dataset')\n",
    "# parser.add_argument('--path_to_save_models', type=str, help='Path to save models')\n",
    "# parser.add_argument('--path_to_save_metrics', type=str, help='Path to save metrics (mAP, CMC, ...)')\n",
    "# parser.add_argument('--version', type=str, help='Path to save models')\n",
    "# parser.add_argument('--eval_freq', type=int, help='Evaluation Frequency along training')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# gpu_ids = args.gpu_ids\n",
    "# base_lr = args.lr\n",
    "# P = args.P\n",
    "# K = args.K\n",
    "\n",
    "# tau = args.tau\n",
    "# beta = args.beta\n",
    "# k1 = args.k1\n",
    "# sampling  = args.sampling\n",
    "#\n",
    "# lambda_hard = args.lambda_hard\n",
    "# number_of_iterations = args.num_iter\n",
    "# momentum_on_feature_extraction = bool(args.momentum_on_feature_extraction)\n",
    "# target = args.target\n",
    "# dir_to_save = args.path_to_save_models\n",
    "# dir_to_save_metrics = args.path_to_save_metrics\n",
    "# version = args.version\n",
    "# eval_freq = args.eval_freq\n",
    "# main.py --gpu_ids=0,1,2,3 --lr=3.5e-4 --P=16 --K=12 --tau=0.04 --beta=0.999 --k1=30 --sampling=mean --lambda_hard=0.5 --num_iter=7 --momentum_on_feature_extraction=0 --target=Duke --path_to_save_models=models --path_to_save_metrics=metrics --version=version_name --eval_freq=5\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Função para exibir a imagem usando HTML\n",
    "def exibir_imagem(imagem_path):\n",
    "    return f'<img src=\"{imagem_path}\" width=\"400\">'\n",
    "\n",
    "\n",
    "from metricas import *\n",
    "\n",
    "html_content= \"\"\n",
    "df = pd.DataFrame({\n",
    "    'k':[], \n",
    "    'lambda_hard':[],\n",
    "    'modelo':[],\n",
    "    'matriz_confusao':[], \n",
    "    'Acuracia':[], \n",
    "    'Precisao':[],\n",
    "    'Recall':[],\n",
    "    'F1-score':[],\n",
    "    'Grafico':[],\n",
    "    'Tipo':[]\n",
    "    })\n",
    "\n",
    "gpus = \"0,1,2,3,4\" \n",
    "for k in [4]:\n",
    "    for lambda_hard in [ 0.0 ]:\n",
    "                \n",
    "        print(f\"**** inicio do teste com ruido em k:{k} e lambda_hard:{lambda_hard} ****\")\n",
    "        \n",
    "        version = f\"teste-03-ruido_{k}_{lambda_hard}\"\n",
    "        \n",
    "        # main(gpu_ids=gpus,base_lr=3.5e-4,P=16,K=k,tau=0.04,beta=0.999,k1=30,sampling=\"random\",lambda_hard=lambda_hard,number_of_iterations=7,momentum_on_feature_extraction=0,target=\"Jadson\",dir_to_save=\"models\",dir_to_save_metrics=\"metrics\",version=version,eval_freq=5,use_ruido=True)\n",
    "        \n",
    "        for metodo in [\"resnet50\",\"osnet\",\"densenet121\",\"mean\"]:\n",
    "            metricas_t, metricas_v = metricas(k=k, lambda_hard=lambda_hard, modelo=metodo)\n",
    "        \n",
    "            for count in range( 0, metricas_t.shape[0] ):\n",
    "                linha = {\n",
    "                'k':[k], \n",
    "                'lambda_hard':[lambda_hard],\n",
    "                'modelo':[metodo],\n",
    "                'matriz_confusao':[f'resultados/MC_{k}_{lambda_hard}_{count}_{metodo}_test.png'], \n",
    "                'Acuracia': [metricas_t[count][0]], \n",
    "                'Precisao': [metricas_t[count][1]], \n",
    "                'Recall':   [metricas_t[count][2]],\n",
    "                'F1-score': [metricas_t[count][3]], \n",
    "                'Grafico':  [f'resultados/grafico_{k}_{lambda_hard}_{count}_{metodo}_test.png'],\n",
    "                'Tipo':     'Test'\n",
    "                    }\n",
    "                df = pd.concat( [df, pd.DataFrame(linha)], axis=0)\n",
    "            \n",
    "            for count in range( 0, metricas_v.shape[0] ):\n",
    "               linha = {\n",
    "               'k':[k], \n",
    "               'lambda_hard':[lambda_hard],\n",
    "               'modelo':[metodo],\n",
    "               'matriz_confusao':[f'resultados/MC_{k}_{lambda_hard}_{count}_{metodo}_valid.png'], \n",
    "               'Acuracia': [metricas_v[count][0]], \n",
    "               'Precisao': [metricas_v[count][1]], \n",
    "               'Recall':   [metricas_v[count][2]], \n",
    "               'F1-score': [metricas_v[count][3]], \n",
    "               'Grafico':  [f'resultados/grafico_{k}_{lambda_hard}_{count}_{metodo}_valid.png'],\n",
    "               'Tipo':     'Valid'\n",
    "                   }\n",
    "               df = pd.concat( [df, pd.DataFrame(linha)], axis=0)\n",
    "        \n",
    "        # Aplicar a função à coluna 'imagem' e criar uma nova coluna 'imagem_exibicao'\n",
    "        df['MC'] = df['matriz_confusao'].apply(exibir_imagem)\n",
    "        df['GR'] = df['Grafico'].apply(exibir_imagem)\n",
    "        \n",
    "        html_content = df[['k', 'lambda_hard', 'Tipo', 'modelo', 'Acuracia', 'Precisao', 'Recall', 'F1-score', 'MC', 'GR']].to_html(escape=False, index=False)\n",
    "        # salvando df em arquivo html\n",
    "        # Use BeautifulSoup para formatar o HTML\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        formatted_html = soup.prettify()\n",
    "        \n",
    "        # Salve o HTML em um arquivo\n",
    "        with open('relatorio-17-3.html', 'w', encoding='utf-8') as file:\n",
    "            file.write('<html><head><title>Meu Relatório</title></head><body>')\n",
    "            file.write(formatted_html)\n",
    "            file.write('</body></html>')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:17:27.464089Z",
     "iopub.status.busy": "2024-01-12T16:17:27.463661Z",
     "iopub.status.idle": "2024-01-12T16:17:27.477064Z",
     "shell.execute_reply": "2024-01-12T16:17:27.475886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>lambda_hard</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Acuracia</th>\n",
       "      <th>Precisao</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>MC</th>\n",
       "      <th>GR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [k, lambda_hard, modelo, matriz_confusao, Acuracia, Precisao, Recall, F1-score, Grafico, Tipo, MC, GR]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Exibir o DataFrame com as imagens\n",
    "display(HTML(html_content))\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
